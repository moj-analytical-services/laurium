{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Customer Feedback analysis with Laurium\n",
    "This notebook explores complex data extraction using laurium and introduces:\n",
    "1) Extracting multiple fields from a piece of text.\n",
    "2) Enforcing output categories using Literals.\n",
    "3) Improving performance with few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from laurium.decoder_models import extract, llm, prompts, pydantic_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Multi-Field Extraction\n",
    "\n",
    "#### Define Complex Output Schemas\n",
    "Extract multiple pieces of structured data simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM instance\n",
    "feedback_llm = llm.create_llm(\n",
    "    llm_platform=\"ollama\", model_name=\"qwen2.5:7b\", temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Enforcing output categories using Literals\n",
    "To restrict the output of the LLM to a specific set of categories, a literal \n",
    "(a list) of categories can be defined in the schema. If the LLM outputs a value\n",
    "when is not present in the literal, the output parser will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for analyzing customer feedback using Literal types for constraints\n",
    "from typing import Literal\n",
    "\n",
    "schema = {\n",
    "    \"sentiment\": Literal[\"positive\", \"negative\", \"neutral\"],\n",
    "    \"urgency\": Literal[1, 2, 3, 4, 5],  # 1-5 scale\n",
    "    \"department\": Literal[\"IT\", \"Support\", \"Product\", \"Sales\", \"Other\"],\n",
    "    \"action_required\": Literal[\"yes\", \"no\"],\n",
    "}\n",
    "\n",
    "descriptions = {\n",
    "    \"sentiment\": \"Customer's emotional tone\",\n",
    "    \"urgency\": \"How quickly this needs attention (1=low, 5=urgent)\",\n",
    "    \"department\": \"Which department should handle this\",\n",
    "    \"action_required\": \"Whether immediate action is needed\",\n",
    "}\n",
    "\n",
    "# Create system message\n",
    "system_message = prompts.create_system_message(\n",
    "    base_message=\"Analyze customer feedback and \"\n",
    "    \"extract structured information.\",\n",
    "    keywords=[\"urgent\", \"complaint\", \"praise\", \"bug\", \"feature\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Improve Accuracy with Examples\n",
    "Add few-shot examples to guide the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot examples for better extraction - JSON format must match schema\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"text\": \"System is down, can't access anything!\",\n",
    "        \"sentiment\": \"negative\",\n",
    "        \"urgency\": 5,\n",
    "        \"department\": \"IT\",\n",
    "        \"action_required\": \"yes\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Love the new interface design\",\n",
    "        \"sentiment\": \"positive\",\n",
    "        \"urgency\": 1,\n",
    "        \"department\": \"Product\",\n",
    "        \"action_required\": \"yes\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create extraction prompt with few-shot examples\n",
    "extraction_prompt = prompts.create_prompt(\n",
    "    system_message=system_message,\n",
    "    examples=few_shot_examples,\n",
    "    example_human_template=\"Feedback: {text}\",\n",
    "    example_assistant_template=\"\"\"{{\n",
    "        \"sentiment\": \"{sentiment}\",\n",
    "        \"urgency\": {urgency},\n",
    "        \"department\": \"{department}\",\n",
    "        \"action_required\": \"{action_required}\"\n",
    "    }}\"\"\",\n",
    "    final_query=\"Feedback: {text}\",\n",
    "    schema=schema,  # Schema formatting still included with examples\n",
    "    descriptions=descriptions,\n",
    ")\n",
    "\n",
    "\n",
    "# define output parser\n",
    "FeedbackModel = pydantic_models.make_dynamic_example_model(\n",
    "    schema=schema,\n",
    "    descriptions=descriptions,\n",
    "    model_name=\"CustomerFeedbackAnalysis\",\n",
    ")\n",
    "\n",
    "# Create extractor and process sample data\n",
    "parser = PydanticOutputParser(pydantic_object=FeedbackModel)\n",
    "extractor = extract.BatchExtractor(\n",
    "    llm=feedback_llm,  # your LLM instance\n",
    "    prompt=extraction_prompt,\n",
    "    parser=parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inspect prompt\n",
    "print(\"Generated system message:\")\n",
    "print(extraction_prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample customer feedback data\n",
    "feedback_data = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [\n",
    "            \"The login system crashed and I lost all my work!\",\n",
    "            \"Really appreciate the new dark mode feature\",\n",
    "            \"Can we get a mobile app version soon?\",\n",
    "            \"Billing charged me twice this month, need help\",\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "results = extractor.process_chunk(feedback_data, text_column=\"text\")\n",
    "print(results.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
