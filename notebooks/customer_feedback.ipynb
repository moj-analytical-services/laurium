{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d72eca8",
   "metadata": {},
   "source": [
    "# Customer Feedback analysis with Laurium\n",
    "This notebook explores complex data extraction using laurium and introduces:\n",
    "1) Extracting multiple fields from a piece of text.\n",
    "2) Enforcing output categories using Literals.\n",
    "3) Improving performance with few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3b82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from laurium.decoder_models import extract, llm, prompts, pydantic_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36aede",
   "metadata": {},
   "source": [
    "### Multi-Field Extraction\n",
    "\n",
    "#### Define Complex Output Schemas\n",
    "Extract multiple pieces of structured data simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5cc396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM instance\n",
    "feedback_llm = llm.create_llm(\n",
    "    llm_platform=\"ollama\", model_name=\"qwen2.5:7b\", temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7d23d",
   "metadata": {},
   "source": [
    "## Enforcing output categories using Literals\n",
    "To restrict the output of the LLM to a specific set of categories, a literal \n",
    "(a list) of categories can be defined in the schema. If the LLM outputs a value\n",
    "when is not present in the literal, the output parser will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71e2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Schema for analyzing customer feedback using Literal types for constraints\n",
    "from typing import Literal\n",
    "\n",
    "schema = {\n",
    "    \"sentiment\": Literal[\"positive\", \"negative\", \"neutral\"],\n",
    "    \"urgency\": int,  # 1-5 scale\n",
    "    \"department\": Literal[\"IT\", \"Support\", \"Product\", \"Sales\", \"Other\"],\n",
    "    \"action_required\": Literal[\"yes\", \"no\"],\n",
    "}\n",
    "\n",
    "descriptions = {\n",
    "    \"sentiment\": \"Customer's emotional tone\",\n",
    "    \"urgency\": \"How quickly this needs attention (1=low, 5=urgent)\",\n",
    "    \"department\": \"Which department should handle this\",\n",
    "    \"action_required\": \"Whether immediate action is needed\",\n",
    "}\n",
    "\n",
    "# Create system message\n",
    "system_message = prompts.create_system_message(\n",
    "    base_message=\"Analyze customer feedback and \" \\\n",
    "    \"extract structured information.\",\n",
    "    keywords=[\"urgent\", \"complaint\", \"praise\", \"bug\", \"feature\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcead746",
   "metadata": {},
   "source": [
    "#### Improve Accuracy with Examples\n",
    "Add few-shot examples to guide the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47029cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot examples for better extraction - JSON format must match schema\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"text\": \"System is down, can't access anything!\",\n",
    "        \"sentiment\": \"negative\",\n",
    "        \"urgency\": 5,\n",
    "        \"department\": \"IT\",\n",
    "        \"action_required\": \"yes\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Love the new interface design\",\n",
    "        \"sentiment\": \"positive\",\n",
    "        \"urgency\": 1,\n",
    "        \"department\": \"Product\",\n",
    "        \"action_required\": \"yes\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create extraction prompt with few-shot examples\n",
    "extraction_prompt = prompts.create_prompt(\n",
    "    system_message=system_message,\n",
    "    examples=few_shot_examples,\n",
    "    example_human_template=\"Feedback: {text}\",\n",
    "    example_assistant_template=\"\"\"{{\n",
    "        \"sentiment\": \"{sentiment}\",\n",
    "        \"urgency\": {urgency},\n",
    "        \"department\": \"{department}\",\n",
    "        \"action_required\": \"{action_required}\"\n",
    "    }}\"\"\",\n",
    "    final_query=\"Feedback: {text}\",\n",
    "    schema=schema,  # Schema formatting still included with examples\n",
    "    descriptions=descriptions,\n",
    ")\n",
    "\n",
    "\n",
    "# define output parser\n",
    "FeedbackModel = pydantic_models.make_dynamic_example_model(\n",
    "    schema=schema,\n",
    "    descriptions=descriptions,\n",
    "    model_name=\"CustomerFeedbackAnalysis\",\n",
    ")\n",
    "\n",
    "# Create extractor and process sample data\n",
    "parser = PydanticOutputParser(pydantic_object=FeedbackModel)\n",
    "extractor = extract.BatchExtractor(\n",
    "    llm=feedback_llm,  # your LLM instance\n",
    "    prompt=extraction_prompt,\n",
    "    parser=parser,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192d942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated system message:\n",
      "Analyze customer feedback and extract structured information.\n",
      "Pay special attention to these keywords: urgent, complaint, praise, bug, feature\n",
      "\n",
      "For each field, extract:\n",
      "- sentiment: Customer's emotional tone\n",
      "- urgency: How quickly this needs attention (1=low, 5=urgent)\n",
      "- department: Which department should handle this\n",
      "- action_required: Whether immediate action is needed\n",
      "\n",
      "Expected output format:\n",
      "{{\n",
      "    \"sentiment\": \"positive|negative|neutral\",\n",
      "    \"urgency\": \"<int>\",\n",
      "    \"department\": \"IT|Support|Product|Sales|Other\",\n",
      "    \"action_required\": \"yes|no\"\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "### inspect prompt\n",
    "print(\"Generated system message:\")\n",
    "print(extraction_prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370871b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            text sentiment  urgency department action_required\n",
      "The login system crashed and I lost all my work!  negative        5         IT             yes\n",
      "     Really appreciate the new dark mode feature  positive        1    Product              no\n",
      "           Can we get a mobile app version soon?   neutral        3    Product              no\n",
      "  Billing charged me twice this month, need help  negative        3    Support             yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample customer feedback data\n",
    "feedback_data = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [\n",
    "            \"The login system crashed and I lost all my work!\",\n",
    "            \"Really appreciate the new dark mode feature\",\n",
    "            \"Can we get a mobile app version soon?\",\n",
    "            \"Billing charged me twice this month, need help\",\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "results = extractor.process_chunk(feedback_data, text_column=\"text\")\n",
    "print(results.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
